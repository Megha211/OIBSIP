{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Detection With Machine Learning\n",
    "## Project by MEGHA MITTAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score , classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As you can see in reading the csv file,  I have given second argument named as encoding ,this encoding parameter specifies the character encoding of the file. In this case, 'ISO-8859-1' is used, which is a common encoding for text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The files contain one message per line. Each line is composed by two columns: v1 contains the label (ham or spam) and v2 contains the raw text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we can see in the info of df dataframe, columns named as unmanned:2, unmanned:3, unmanned:4 are irrelevant, so we have to drop them before moving towards more preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have 5572 rows of data, which is message and its corresponding label which can be either a ham or a spam email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['label', 'message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's rename the column names to more logical names as message and label for better understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'message'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have 403 emails which are duplicate of each other. So, lets remove these so that our model should not get overfitted while learning the same emails which are residing in our dataset(spam.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop_duplicates(keep='first')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  As you can notice the argument is setted in duplicate function which is the \"keep\" parameter is set to 'first'. This means that when duplicate rows are found, only the first occurrence of each duplicate row will be kept, and all subsequent occurrences will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice in our dataset, the data is in the text format, but models or neural networks understands numbers, so we have to convert our text data into number representation of them. For this task, lets use labelencoding, or you can use other also like word2vec, embeddings in the nltk library etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "5568      0              Will Ì_ b going to esplanade fr home?\n",
       "5569      0  Pity, * was in mood for that. So...any other s...\n",
       "5570      0  The guy did some bitching but I acted like i'd...\n",
       "5571      0                         Rofl. Its true to its name\n",
       "\n",
       "[5169 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder= LabelEncoder()\n",
    "df['label']= encoder.fit_transform(df['label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4516\n",
       "1     653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 4516 ham emails and rest 653 are spam emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x30002ee90>,\n",
       "  <matplotlib.patches.Wedge at 0x300056090>],\n",
       " [Text(-0.42519443516002475, -1.0144997251399075, 'ham'),\n",
       "  Text(0.42519434017570373, 1.014499764949479, 'spam')],\n",
       " [Text(-0.23192423736001347, -0.5533634864399495, '87.4%'),\n",
       "  Text(0.2319241855503838, 0.5533635081542612, '12.6%')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(df['label'].value_counts(), labels=['ham', 'spam'], autopct='%1.1f%%', startangle=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can easily observe from the pie chart that , there is class imbalance problem , i.e we ham more data for ham emails then for the spam emails. This problem can leads us to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4516\n",
       "1    4516\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Create an instance of RandomOverSampler\n",
    "oversampler = RandomOverSampler()\n",
    "\n",
    "# Resample the dataset\n",
    "X_resampled, y_resampled = oversampler.fit_resample(df['message'].values.reshape(-1, 1), df['label'])\n",
    "\n",
    "# Create a new balanced dataframe\n",
    "df_balanced = pd.DataFrame({'message': X_resampled.flatten(), 'label': y_resampled})\n",
    "\n",
    "# Check the class distribution\n",
    "df_balanced['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9027</th>\n",
       "      <td>Urgent Please call 09066612661 from landline. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9028</th>\n",
       "      <td>You have an important customer service announc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9029</th>\n",
       "      <td>Hi babe its Jordan, how r u? Im home from abro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9030</th>\n",
       "      <td>Free entry to the gr8prizes wkly comp 4 a chan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9031</th>\n",
       "      <td>Refused a loan? Secured or Unsecured? Can't ge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9032 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  label\n",
       "0     Go until jurong point, crazy.. Available only ...      0\n",
       "1                         Ok lar... Joking wif u oni...      0\n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3     U dun say so early hor... U c already then say...      0\n",
       "4     Nah I don't think he goes to usf, he lives aro...      0\n",
       "...                                                 ...    ...\n",
       "9027  Urgent Please call 09066612661 from landline. ...      1\n",
       "9028  You have an important customer service announc...      1\n",
       "9029  Hi babe its Jordan, how r u? Im home from abro...      1\n",
       "9030  Free entry to the gr8prizes wkly comp 4 a chan...      1\n",
       "9031  Refused a loan? Secured or Unsecured? Can't ge...      1\n",
       "\n",
       "[9032 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we have balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>number_characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  number_characters\n",
       "0  Go until jurong point, crazy.. Available only ...      0                111\n",
       "1                      Ok lar... Joking wif u oni...      0                 29\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1                155\n",
       "3  U dun say so early hor... U c already then say...      0                 49\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0                 61"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['number_characters'] = df_balanced['message'].apply(len)\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1002)>\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/megha/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/punkt'\n    - '/punkt'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/punkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_words\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_balanced\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/punkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_words\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/megha/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/punkt'\n    - '/punkt'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt', download_dir='/punkt')\n",
    "# import os\n",
    "# nltk.data.path.append('/punkt')\n",
    "# df_balanced['number_words'] = df_balanced['message'].apply(lambda x: len(nltk.word_tokenize(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1002)>\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/megha/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/punkt'\n    - '/punkt'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_words\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_balanced\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_balanced)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[45], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_words\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_balanced)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/megha/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/punkt'\n    - '/punkt'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "df_balanced['number_words'] = df_balanced['message'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "\n",
    "print(df_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
